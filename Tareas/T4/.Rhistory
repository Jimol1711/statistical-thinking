ratio.real <- sum(bites) / (n * 8)
simulated_bites <- sapply(samples, function(p) {
rbinom(n, size = 8, prob = p)
})
simulated_ratios <- colSums(simulated_bites) / (n * 8)
ggplot() +
geom_density(aes(simulated_ratios)) +
geom_vline(aes(xintercept = ratio.real), color = "red") +
labs(x = "Ratio de Carteros Mordidos", y = "Densidad", title = "Distribución de Ratios Simulados vs. Ratio Real")
first_month <- "bites_month_7"
second_month <- "bites_month_8"
# Filter bitten on first month
mordidos_first <- dataMordidas[dataMordidas[[first_month]] == 1, ]
real_recuento <- sum(mordidos_first[[second_month]])
n_mordidos_first <- nrow(mordidos_first)
# Simulate 10000 times
simulated_counts <- sapply(samples, function(p) {
rbinom(1, size = n_mordidos_first, prob = p)
})
ggplot() +
geom_density(aes(simulated_counts), alpha = 0.5) +
geom_vline(aes(xintercept = real_recuento), color = "red", linetype = "dashed") +
labs(x = "Recuento de Carteros Mordidos",
y = "Densidad",
title = "Distribución de Simulaciones vs. Recuento Real") +
theme_minimal()
# Leer información
data_notas <- read.csv("notas.csv")
data_vector <- as.numeric(data_notas$Notas)
# Función para crear likelihood dado mu y sigma
grid_function <- function(mu, sigma){
sum(dnorm(data_vector, mean = mu, sd = sigma, log = TRUE))
}
# Valores de la grilla
grid_mu <- seq(1, 7, length.out = 100)
grid_sigma <- seq(0.5, 1.5, length.out = 100)
# Se crea la grilla 2d
data_grid <- expand_grid(grid_mu,grid_sigma)
# Se guarda la likelihod
data_grid$likelihood <- map2(data_grid$grid_mu,data_grid$grid_sigma, grid_function)
# Se transforma el forma de map2 a una columna
data_grid <- unnest(data_grid,cols = c("likelihood"))
# Valores de los priors
prior_mu <- rep(1, length(grid_mu))
# Se resta 0.5 para mantener el argumento de la distribución en [0,1]
prior_sigma <- dbeta(grid_sigma - 0.5, shape1 = 3, shape2 = 6)
# Se crea la grilla 2d de priors
prior <- expand_grid(prior_mu,prior_sigma)
# Se calculan los valores del prior
data_grid$prior <-  map2(prior$prior_mu,prior$prior_sigma, prod)
data_grid <- unnest(data_grid,cols = c("prior"))
# Se calcula el posterior
data_grid$unstd_posterior <-  data_grid$likelihood * data_grid$prior
# Se estandariza el posterior
data_grid$posterior <- data_grid$unstd_posterior/sum(data_grid$unstd_posterior)
# Se ajustan los valores de la posterior para que no sean valores tan pequeños
data_grid$posterior <- (data_grid$posterior - min(data_grid$posterior))/(max(data_grid$posterior)-min(data_grid$posterior))
plot(grid_sigma, prior_sigma, type = "l", col = "blue",
main = "Prior para sigma usando Beta(3, 8)",
xlab = expression(sigma), ylab = "Densidad de probabilidad")
# Añadir una línea horizontal para referencia
abline(h = 0, col = "gray")
# Punto de referencia
valor_x <- mean(data_vector)
valor_y <- 0.8
# Gráfico
punto_comparacion <- tibble(x = valor_x, y = valor_y)
plt <- data_grid %>%
ggplot(aes(x = grid_mu, y = grid_sigma)) +
geom_raster(aes(fill = posterior),
interpolate = T
)+
geom_point(x = valor_x, y = valor_y, size = 1.3,color="white")+
geom_label(
data = punto_comparacion, aes(x, y),
label = "Punto Comparación",
fill = "green",
color = "black",
nudge_y = 0, # Este parametro desplaza la caja por el eje y
nudge_x = 1 # Este parametro desplaza la caja por el eje x
)+
scale_fill_viridis_c() +
labs(
title = "Posterior para Mean y Standard Deviation",
x = expression(mu ["Mean"]),
y = expression(sigma ["Standar Deviation"])
) +
theme(panel.grid = element_blank())
plt
install.packages(c("mvtnorm", "loo", "coda", "shape"), repos = "https://cloud.r-project.org/", dependencies = TRUE)
# Codificamos los datos
install.packages("rethinking", type = "source")
install.packages("rethinking")
x <- 1:length(data_grid$posterior)
# Sampleamos los indices
posterior_samples_aux <- sample(x,size = 1e4, replace = T, prob = data_grid$posterior)
# Obtenemos los verdaderos valores de la sampling distribution
posterior_samples <- data_grid[posterior_samples_aux,]
# Obtenemos solos los valores relevantes para la densidad
df <- data.frame(posterior_samples$grid_mu,posterior_samples$grid_sigma)
# Realizamos las densidades
dens(df)
poke.df <- read.csv("Pokemon.csv")
# Model variables
data <- pokemon[, c("Sp..Atk", "Attack")]
install.packages("rethinking")
# Model variables
data <- pokemon[, c("Sp..Atk", "Attack")]
# Model variables
data <- poke.df[, c("Sp..Atk", "Attack")]
# Bayesian model
# Equations for the model
model <- alist(
Sp..Atk ~ dnorm(mu, sigma),   # Likelihood
mu <- alpha + beta * Attack,  # Linear model
alpha ~ dnorm(100, 50),         # Intercept Prior
beta ~ dnorm(1, 0.5),          # Slope Prior
sigma ~ dunif(0, 200)              # Standard Deviation Prior
)
# Fit the model with Laplace Approximation
fit <- quap(
model,
data = data
)
# Summary
precis(fit)
# Graph the model and uncertainty lines
plot(data$Attack, data$Sp..Atk, pch = 16, col = "blue", xlab = "Attack", ylab = "Sp..Atk")
post <- extract.samples(fit)
for (i in 1:100) {
curve(post$alpha[i] + post$beta[i] * x, add = TRUE, col = alpha("red", 0.2))
}
# Manipulación de estructuras
library(tidyverse)
library(dplyr)
library(tidyr)
library(purrr)
# Para realizar plots
library(scatterplot3d)
library(ggplot2)
library(plotly)
# Manipulación de varios plots en una imagen.
library(gridExtra)
# Análisis bayesiano
library(rethinking)
install.packages("rethinking")
install.packages(c("mvtnorm","loo","coda", "shape"), repos="https://cloud.r-project.org/",dependencies=TRUE)
options(repos=c(getOption('repos'), rethinking='http://xcelab.net/R'))
install.packages('rethinking',type='source')
dataMordidas <- read.csv("no_mordidas.csv", header = TRUE)
cols <- c("bites_month_1", "bites_month_2", "bites_month_3",
"bites_month_4", "bites_month_5", "bites_month_6",
"bites_month_7", "bites_month_8")
# Prior parameters
grid_len <- 250
p_grid <- seq(from=0, to=1, length.out = grid_len)
prior <- dnorm(p_grid, mean = 0.6, sd = 0.05)
posteriors <- c()
counted.months <- c()
p_grids <- rep(p_grid, 4)
for (n in c(1, 2, 4, 8)) {
bites <- rowSums(as.matrix(dataMordidas[, 1:n]))
likelihood <- dbinom(bites, size = n, prob = p_grid)
unstd.posterior <- prior * likelihood
posterior <- unstd.posterior / sum(unstd.posterior)
posteriors <- c(posteriors, posterior)
counted.months <- c(counted.months, rep(n, grid_len))
}
post.df <- data.frame("grid" = p_grids, "posterior" = posteriors, "months" = counted.months)
# Visualize
ggplot(post.df) +
geom_line(aes(x = grid, y = posteriors)) +
facet_grid(months ~ .) +
labs(x = "Probabilidad de Mordida", y = "Posterior", title = "Distribución Posterior por Número de Meses")
cols <- c("bites_month_1", "bites_month_2", "bites_month_3",
"bites_month_4", "bites_month_5", "bites_month_6",
"bites_month_7", "bites_month_8")
# Prior uniforme
grid_len <- 250
p_grid <- seq(from=0, to=1, length.out = grid_len)
prior <- rep(1, grid_len)
posteriors <- c()
counted.months <- c()
p_grids <- rep(p_grid, 4)
for (n in c(1, 2, 4, 8)) {
bites <- rowSums(as.matrix(dataMordidas[, 1:n]))
likelihood <- dbinom(bites, size = n, prob = p_grid)
unstd.posterior <- prior * likelihood
posterior <- unstd.posterior / sum(unstd.posterior)
posteriors <- c(posteriors, posterior)
}
post.df$posterior2 <- posteriors
# Graficar los resultados
ggplot(post.df) +
geom_line(aes(x = grid, y = posteriors)) +
facet_grid(months ~ .) +
labs(x = "Probabilidad de Mordida", y = "Posterior", title = "Distribución Posterior por Número de Meses")
for (n in c(1, 2, 4, 8)) {
W <- sum(dataMordidas[, 1:n])
L <- n * 250 - W
# Adjust model
res <- quap(
alist(
W ~ dbinom(L, p),  # Likelihood
p ~ dunif(0, 1)    # Prior
),
data = list(W = W, L = L)
)
df <- precis(res)
# Graph the posterior curves
curve(dnorm(x, df$mean, df$sd), lty=2, add=FALSE,
xlab = "Probabilidad de mordida", ylab = "Densidad",
main = paste("Distribución posterior - Meses:", n))
}
grid_len <- 1000
p_grid <- seq(0, 1, length.out = grid_len)
prior <- dnorm(p_grid, mean = 0.6, sd = 0.05)
bites <- rowSums(as.matrix(dataMordidas[, 1:8]))
likelihood <- dbinom(bites, size = 8, prob = p_grid)
unstd.posterior <- prior * likelihood
posterior <- unstd.posterior / sum(unstd.posterior)
samples <- sample(p_grid, prob = posterior, size = 1e4, replace = TRUE)
dens(samples)
# Intervalos:
proporcion_0_035 <- mean(samples >= 0 & samples <= 0.35)
proporcion_035_045 <- mean(samples > 0.35 & samples <= 0.45)
proporcion_mayor_045 <- mean(samples > 0.45)
# Print proportions
cat("Proporción en el rango [0, 0.35]:", proporcion_0_035, "\n")
cat("Proporción en el rango (0.35, 0.45]:", proporcion_035_045, "\n")
cat("Proporción en el rango (>0.45):", proporcion_mayor_045, "\n")
# Function to calculate credible interval for given prob
cred_interval <- function(samples, prob) {
quantiles <- quantile(samples, probs = c((1 - prob) / 2, 1 - (1 - prob) / 2))
return(quantiles)
}
# Calculate intervals
cred_50 <- cred_interval(samples, 0.50)
cred_75 <- cred_interval(samples, 0.75)
cred_95 <- cred_interval(samples, 0.95)
cat("Intervalo de Credibilidad 50%: [", cred_50[1], ", ", cred_50[2], "]\n")
cat("Intervalo de Credibilidad 75%: [", cred_75[1], ", ", cred_75[2], "]\n")
cat("Intervalo de Credibilidad 95%: [", cred_95[1], ", ", cred_95[2], "]\n")
# Calculate intervals with HPDI function from rethinking
hdpi_50 <- HPDI(samples, prob = 0.50)
hdpi_75 <- HPDI(samples, prob = 0.75)
hdpi_95 <- HPDI(samples, prob = 0.95)
cat("Intervalo HDPI 50%: [", hdpi_50[1], ", ", hdpi_50[2], "]\n")
cat("Intervalo HDPI 75%: [", hdpi_75[1], ", ", hdpi_75[2], "]\n")
cat("Intervalo HDPI 95%: [", hdpi_95[1], ", ", hdpi_95[2], "]\n")
bites <- rowSums(as.matrix(dataMordidas[, 1:8]))
n <- nrow(dataMordidas)
ratio.real <- sum(bites) / (n * 8)
simulated_bites <- sapply(samples, function(p) {
rbinom(n, size = 8, prob = p)
})
simulated_ratios <- colSums(simulated_bites) / (n * 8)
ggplot() +
geom_density(aes(simulated_ratios)) +
geom_vline(aes(xintercept = ratio.real), color = "red") +
labs(x = "Ratio de Carteros Mordidos", y = "Densidad", title = "Distribución de Ratios Simulados vs. Ratio Real")
first_month <- "bites_month_7"
second_month <- "bites_month_8"
# Filter bitten on first month
mordidos_first <- dataMordidas[dataMordidas[[first_month]] == 1, ]
real_recuento <- sum(mordidos_first[[second_month]])
n_mordidos_first <- nrow(mordidos_first)
# Simulate 10000 times
simulated_counts <- sapply(samples, function(p) {
rbinom(1, size = n_mordidos_first, prob = p)
})
ggplot() +
geom_density(aes(simulated_counts), alpha = 0.5) +
geom_vline(aes(xintercept = real_recuento), color = "red", linetype = "dashed") +
labs(x = "Recuento de Carteros Mordidos",
y = "Densidad",
title = "Distribución de Simulaciones vs. Recuento Real") +
theme_minimal()
# Leer información
data_notas <- read.csv("notas.csv")
data_vector <- as.numeric(data_notas$Notas)
# Función para crear likelihood dado mu y sigma
grid_function <- function(mu, sigma){
sum(dnorm(data_vector, mean = mu, sd = sigma, log = TRUE))
}
# Valores de la grilla
grid_mu <- seq(1, 7, length.out = 100)
grid_sigma <- seq(0.5, 1.5, length.out = 100)
# Se crea la grilla 2d
data_grid <- expand_grid(grid_mu,grid_sigma)
# Se guarda la likelihod
data_grid$likelihood <- map2(data_grid$grid_mu,data_grid$grid_sigma, grid_function)
# Se transforma el forma de map2 a una columna
data_grid <- unnest(data_grid,cols = c("likelihood"))
# Valores de los priors
prior_mu <- rep(1, length(grid_mu))
# Se resta 0.5 para mantener el argumento de la distribución en [0,1]
prior_sigma <- dbeta(grid_sigma - 0.5, shape1 = 3, shape2 = 6)
# Se crea la grilla 2d de priors
prior <- expand_grid(prior_mu,prior_sigma)
# Se calculan los valores del prior
data_grid$prior <-  map2(prior$prior_mu,prior$prior_sigma, prod)
data_grid <- unnest(data_grid,cols = c("prior"))
# Se calcula el posterior
data_grid$unstd_posterior <-  data_grid$likelihood * data_grid$prior
# Se estandariza el posterior
data_grid$posterior <- data_grid$unstd_posterior/sum(data_grid$unstd_posterior)
# Se ajustan los valores de la posterior para que no sean valores tan pequeños
data_grid$posterior <- (data_grid$posterior - min(data_grid$posterior))/(max(data_grid$posterior)-min(data_grid$posterior))
plot(grid_sigma, prior_sigma, type = "l", col = "blue",
main = "Prior para sigma usando Beta(3, 8)",
xlab = expression(sigma), ylab = "Densidad de probabilidad")
# Añadir una línea horizontal para referencia
abline(h = 0, col = "gray")
# Punto de referencia
valor_x <- mean(data_vector)
valor_y <- 0.8
# Gráfico
punto_comparacion <- tibble(x = valor_x, y = valor_y)
plt <- data_grid %>%
ggplot(aes(x = grid_mu, y = grid_sigma)) +
geom_raster(aes(fill = posterior),
interpolate = T
)+
geom_point(x = valor_x, y = valor_y, size = 1.3,color="white")+
geom_label(
data = punto_comparacion, aes(x, y),
label = "Punto Comparación",
fill = "green",
color = "black",
nudge_y = 0, # Este parametro desplaza la caja por el eje y
nudge_x = 1 # Este parametro desplaza la caja por el eje x
)+
scale_fill_viridis_c() +
labs(
title = "Posterior para Mean y Standard Deviation",
x = expression(mu ["Mean"]),
y = expression(sigma ["Standar Deviation"])
) +
theme(panel.grid = element_blank())
plt
# Codificamos los datos
x <- 1:length(data_grid$posterior)
# Sampleamos los indices
posterior_samples_aux <- sample(x,size = 1e4, replace = T, prob = data_grid$posterior)
# Obtenemos los verdaderos valores de la sampling distribution
posterior_samples <- data_grid[posterior_samples_aux,]
# Obtenemos solos los valores relevantes para la densidad
df <- data.frame(posterior_samples$grid_mu,posterior_samples$grid_sigma)
# Realizamos las densidades
dens(df)
poke.df <- read.csv("Pokemon.csv")
# Model variables
data <- poke.df[, c("Sp..Atk", "Attack")]
# Bayesian model
# Equations for the model
model <- alist(
Sp..Atk ~ dnorm(mu, sigma),   # Likelihood
mu <- alpha + beta * Attack,  # Linear model
alpha ~ dnorm(100, 50),         # Intercept Prior
beta ~ dnorm(1, 0.5),          # Slope Prior
sigma ~ dunif(0, 200)              # Standard Deviation Prior
)
# Fit the model with Laplace Approximation
fit <- quap(
model,
data = data
)
# Summary
precis(fit)
# Graph the model and uncertainty lines
plot(data$Attack, data$Sp..Atk, pch = 16, col = "blue", xlab = "Attack", ylab = "Sp..Atk")
post <- extract.samples(fit)
for (i in 1:100) {
curve(post$alpha[i] + post$beta[i] * x, add = TRUE, col = alpha("red", 0.2))
}
ggplot() +
geom_point(aes(x=poke.df$Attack, y=poke.df$Sp..Atk), color="red") +
geom_line(aes(x=, y=), color="orange") +
geom_ribbon(aes(x=, y=, ymin=, ymax=), alpha=0.3, fill="orange") +
geom_ribbon(aes(x=, y=, ymin=, ymax=), alpha=0.1, fill="orange")
# Generate predictions on the fitted model
attack_seq <- seq(min(data$Attack), max(data$Attack), length.out = 100)
predicted_mean <- link(fit, data = list(Attack = attack_seq))
mean_pred <- apply(predicted_mean, 2, mean)
ci_mean <- apply(predicted_mean, 2, PI, prob = 0.95)
predicted_values <- sim(fit, data = list(Attack = attack_seq))
ci_pred <- apply(predicted_values, 2, PI, prob = 0.95)
plot(data$Attack, data$Sp..Atk, pch = 16, col = "blue", xlab = "Attack", ylab = "Sp..Atk")
# Graph lines and credible intervals
lines(attack_seq, mean_pred, col = "red", lwd = 2)
polygon(c(attack_seq, rev(attack_seq)),
c(ci_mean[1, ], rev(ci_mean[2, ])),
col = alpha("red", 0.2), border = NA)
polygon(c(attack_seq, rev(attack_seq)),
c(ci_pred[1, ], rev(ci_pred[2, ])),
col = alpha("blue", 0.2), border = NA)
legend("topleft", legend = c("Media predicha (MAP)", "IC 95% (media)", "IC 95% (valores)"),
col = c("red", alpha("red", 0.2), alpha("blue", 0.2)), lwd = c(2, NA, NA), pch = c(NA, 15, 15),
pt.cex = 2, bty = "n", cex = 0.8, bg = "white")
grid_len <- 1000
p_grid <- seq(0, 1, length.out = grid_len)
prior <- rep(1, grid_len) # dnorm(p_grid, mean = 0.6, sd = 0.05)
bites <- rowSums(as.matrix(dataMordidas[, 1:8]))
likelihood <- dbinom(bites, size = 8, prob = p_grid)
unstd.posterior <- prior * likelihood
posterior <- unstd.posterior / sum(unstd.posterior)
samples <- sample(p_grid, prob = posterior, size = 1e4, replace = TRUE)
dens(samples)
# Manipulación de estructuras
library(tidyverse)
library(dplyr)
library(tidyr)
library(purrr)
# Para realizar plots
library(scatterplot3d)
library(ggplot2)
library(plotly)
# Manipulación de varios plots en una imagen.
library(gridExtra)
# Análisis bayesiano
library(rethinking)
dataMordidas <- read.csv("no_mordidas.csv", header = TRUE)
cols <- c("bites_month_1", "bites_month_2", "bites_month_3",
"bites_month_4", "bites_month_5", "bites_month_6",
"bites_month_7", "bites_month_8")
# Prior uniforme
grid_len <- 250
p_grid <- seq(from=0, to=1, length.out = grid_len)
prior <- rep(1, grid_len)
posteriors <- c()
counted.months <- c()
p_grids <- rep(p_grid, 4)
for (n in c(1, 2, 4, 8)) {
bites <- rowSums(as.matrix(dataMordidas[, 1:n]))
likelihood <- dbinom(bites, size = n, prob = p_grid)
unstd.posterior <- prior * likelihood
posterior <- unstd.posterior / sum(unstd.posterior)
posteriors <- c(posteriors, posterior)
}
post.df$posterior2 <- posteriors
# Graficar los resultados
ggplot(post.df) +
geom_line(aes(x = grid, y = posteriors)) +
facet_grid(months ~ .) +
labs(x = "Probabilidad de Mordida", y = "Posterior", title = "Distribución Posterior por Número de Meses")
grid_len <- 1000
p_grid <- seq(0, 1, length.out = grid_len)
prior <- rep(1, grid_len) # dnorm(p_grid, mean = 0.6, sd = 0.05)
bites <- rowSums(as.matrix(dataMordidas[, 1:8]))
likelihood <- dbinom(bites, size = 8, prob = p_grid)
unstd.posterior <- prior * likelihood
posterior <- unstd.posterior / sum(unstd.posterior)
samples <- sample(p_grid, prob = posterior, size = 1e4, replace = TRUE)
dens(samples)
# Intervalos:
proporcion_0_035 <- mean(samples >= 0 & samples <= 0.35)
proporcion_035_045 <- mean(samples > 0.35 & samples <= 0.45)
proporcion_mayor_045 <- mean(samples > 0.45)
# Print proportions
cat("Proporción en el rango [0, 0.35]:", proporcion_0_035, "\n")
cat("Proporción en el rango (0.35, 0.45]:", proporcion_035_045, "\n")
cat("Proporción en el rango (>0.45):", proporcion_mayor_045, "\n")
# Function to calculate credible interval for given prob
cred_interval <- function(samples, prob) {
quantiles <- quantile(samples, probs = c((1 - prob) / 2, 1 - (1 - prob) / 2))
return(quantiles)
}
# Calculate intervals
cred_50 <- cred_interval(samples, 0.50)
cred_75 <- cred_interval(samples, 0.75)
cred_95 <- cred_interval(samples, 0.95)
cat("Intervalo de Credibilidad 50%: [", cred_50[1], ", ", cred_50[2], "]\n")
cat("Intervalo de Credibilidad 75%: [", cred_75[1], ", ", cred_75[2], "]\n")
cat("Intervalo de Credibilidad 95%: [", cred_95[1], ", ", cred_95[2], "]\n")
cat("Intervalo de Credibilidad 75%: [", cred_75[1], ", ", cred_75[2], "]\n")
cat("Intervalo de Credibilidad 95%: [", cred_95[1], ", ", cred_95[2], "]\n")
# Calculate intervals with HPDI function from rethinking
hdpi_50 <- HPDI(samples, prob = 0.50)
hdpi_75 <- HPDI(samples, prob = 0.75)
hdpi_95 <- HPDI(samples, prob = 0.95)
cat("Intervalo HDPI 50%: [", hdpi_50[1], ", ", hdpi_50[2], "]\n")
cat("Intervalo HDPI 75%: [", hdpi_75[1], ", ", hdpi_75[2], "]\n")
cat("Intervalo HDPI 95%: [", hdpi_95[1], ", ", hdpi_95[2], "]\n")
bites <- rowSums(as.matrix(dataMordidas[, 1:8]))
n <- nrow(dataMordidas)
ratio.real <- sum(bites) / (n * 8)
simulated_bites <- sapply(samples, function(p) {
rbinom(n, size = 8, prob = p)
})
simulated_ratios <- colSums(simulated_bites) / (n * 8)
ggplot() +
geom_density(aes(simulated_ratios)) +
geom_vline(aes(xintercept = ratio.real), color = "red") +
labs(x = "Ratio de Carteros Mordidos", y = "Densidad", title = "Distribución de Ratios Simulados vs. Ratio Real")
first_month <- "bites_month_7"
second_month <- "bites_month_8"
# Filter bitten on first month
mordidos_first <- dataMordidas[dataMordidas[[first_month]] == 1, ]
real_recuento <- sum(mordidos_first[[second_month]])
n_mordidos_first <- nrow(mordidos_first)
# Simulate 10000 times
simulated_counts <- sapply(samples, function(p) {
rbinom(1, size = n_mordidos_first, prob = p)
})
ggplot() +
geom_density(aes(simulated_counts), alpha = 0.5) +
geom_vline(aes(xintercept = real_recuento), color = "red", linetype = "dashed") +
labs(x = "Recuento de Carteros Mordidos",
y = "Densidad",
title = "Distribución de Simulaciones vs. Recuento Real") +
theme_minimal()
