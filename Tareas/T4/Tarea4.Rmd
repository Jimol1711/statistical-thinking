---
title: "Tarea 4"
output:
  html_document:
    df_print: paged
---

![](banner.png)

<center> <h1>Tarea 4: Bayesian Inference</h1> </center>
<center><strong>CC6104: Statistical Thinking</strong></center>
#### **Integrantes :** 

- Franco Cattani
- Juan Molina

#### **Cuerpo Docente:**

-   Profesor: Felipe Bravo M.
-   Auxiliar: Martín Paredes, Benjamín Farías
-   Ayudantes: Scarleth Betancurt, Emilio Díaz, Kevin Iturra, Renzo Zanca
            

### **Índice:**

1. [Objetivo](#id1)
2. [Instrucciones](#id2)
3. [Referencias](#id3)
4. [Elaboración de Código](#id5)

### **Objetivo**<a name="id1"></a>

Bienvenides a la cuarta tarea del curso Statistical Thinking. Esta tarea tiene como objetivo evaluar los contenidos teóricos de la primera parte del curso, los cuales se enfocan principalmente en introducirlos en la estadística bayesiana. Si aún no han visto las clases, se recomienda visitar los enlaces de las referencias.

La tarea consta de una parte práctica con el fin de introducirlos a la programación en R enfocada en el análisis estadístico de datos. 

### **Instrucciones:**<a name="id2"></a>

- La tarea se realiza en grupos de **máximo 2 personas**. Pero no existe problema si usted desea hacerla de forma individual.
- La entrega es a través de u-cursos a más tardar el día estipulado en la misma plataforma. A las tareas atrasadas se les descontará un punto por día.
- El formato de entrega es este mismo **Rmarkdown** y un **html** con la tarea desarrollada. Por favor compruebe que todas las celdas han sido ejecutadas en el archivo html.
- Al momento de la revisión tu código será ejecutado. Por favor verifica que tu entrega no tenga errores de compilación.
- No serán revisadas tareas desarrolladas en Python.
- Está **PROHIBIDO** la copia o compartir las respuestas entre integrantes de diferentes grupos.
- Pueden realizar consultas de la tarea a través de U-cursos y/o del canal de Discord del curso. 


### **Referencias:**<a name="id3"></a>

Slides de las clases:

- [Introduction to Bayesian Inference](https://github.com/dccuchile/CC6104/blob/master/slides/3_1_ST-bayesian.pdf)
- [Summarizing the Posterior](https://github.com/dccuchile/CC6104/blob/master/slides/3_2_ST-posterior.pdf)


Videos de las clases:

- Introduction to Bayesian Inference: [video1](https://youtu.be/Gf2uuElPH0g) [video2](https://youtu.be/5ZZ3PTPdZQw) [video3](https://youtu.be/d_jXwM_-5jc) [video4](https://youtu.be/yZW1V3X4J94) [video5](https://youtu.be/-fw0ktR7psM) [video6](https://youtu.be/0oK9M82sw8Q) [video7](https://youtu.be/u7Qdw5rDDDU)
- Summarizing the Posterior: [video1](https://youtu.be/67o8wcZsgtk)  [video2](https://youtu.be/Xr8S1Uv_5GQ) [video3](https://youtu.be/XJKyW4tYp_0) [video4](https://youtu.be/OMipgV727wo)

Documentación:

- [rethinking](https://github.com/rmcelreath/rethinking)
- [tidyr](https://tidyr.tidyverse.org)
- [purrr](https://purrr.tidyverse.org)
- [dplyr](https://dplyr.tidyverse.org)
- [ggplot2](https://ggplot2.tidyverse.org/)


#Elaboración de Código<a name="id5"></a>

En la siguiente sección deberá resolver cada uno de los experimentos computacionales a través de la programación en R. Para esto se le aconseja que cree funciones en R, ya que le facilitará la ejecución de gran parte de lo solicitado.

Para el desarrollo preste mucha atención en los enunciados, ya que se le solicitará la implementación de métodos sin uso de funciones predefinidas. Por otro lado, Las librerías permitidas para desarrollar de la tarea 4 son las siguientes:

```{r, eval=FALSE}
# Manipulación de estructuras
library(tidyverse)
library(dplyr)
library(tidyr)
library(purrr)

# Para realizar plots
library(scatterplot3d)
library(ggplot2)
library(plotly)

# Manipulación de varios plots en una imagen.
library(gridExtra)

# Análisis bayesiano
library(rethinking)
```

Si no tiene instalada la librería “rethinking”, ejecute las siguientes líneas de código para instalar la librería:

```{r, eval=FALSE}
install.packages("rethinking")
```

En caso de tener problemas al momento de instalar la librería con el código anterior, utilice el siguiente chunk:

```{r, eval=FALSE}
install.packages(c("mvtnorm","loo","coda", "shape"), repos="https://cloud.r-project.org/",dependencies=TRUE)
options(repos=c(getOption('repos'), rethinking='http://xcelab.net/R'))
install.packages('rethinking',type='source')
```

### Pregunta 1:

Un conjunto de carteros aburridos de las mordidas de perros ha decidido realizar un catastro de mordidas recibidas por los empleados de su empresa en un periodo de 8 meses, planeando en base a estos datos realizar inferencia bayesiana. Los datos de las mordidas estas datos por el dataset `no+mordidas.csv`, en donde cada fila representa las mordidas recibidas por diferentes carteros y las columnas señalan si fue mordido o no el cartero en los meses de estudio (si fue mordido es señalado con un 1, de lo contrario es señalado con un 0). Cabe señalar que un cartero no puede ser mordido mas de una vez al mes, ya que el damnificado recibe licencia de todo un mes tras la mordida, reincorporándose el siguiente mes al trabajo.

```{r, eval=FALSE}
dataMordidas <- read.csv("no_mordidas.csv", header = TRUE)
```

- [] Uno de los carteros le comenta que, según él, lo han mordido 6 de cada 10 veces, y le recomienda usar esta información como antecedente para su inferencia. Para ello considere como prior la distribución gausseana de media 0.6 y desviación estándar 0.05. Programe el método grid approximation para 1, 2, 4 y 8 meses. ¿Como van cambiando las curvas posterior?

```{r, eval=FALSE}
cols <- c("bites_month_1", "bites_month_2", "bites_month_3",
          "bites_month_4", "bites_month_5", "bites_month_6",
          "bites_month_7", "bites_month_8")

# Prior parameters
grid_len <- 100
p_grid <- seq(0, 1, length.out = grid_len)  # Grid of probabilities
prior <- dnorm(p_grid, mean = 0.6, sd = 0.05) # Prior

posteriors <- c()
counted.months <- c()
p_grids <- rep(p_grid, 4)

for (n in c(1, 2, 4, 8)) {
  bites <- rowSums(as.matrix(dataMordidas[, 1:n]))

  likelihood <- dbinom(bites, size = n, prob = p_grid)
  
  unstd.posterior <- prior * likelihood
  posterior <- unstd.posterior / sum(unstd.posterior)
  
  posteriors <- c(posteriors, rep(posterior,grid_len))
  counted.months <- c(counted.months, rep(n, grid_len))
}

post.df <- data.frame("grid" = rep(p_grid, 4), "posterior" = posteriors, "months" = counted.months)

# Graficar los resultados
ggplot(post.df) +
  geom_line(aes(x = grid, y = posteriors)) +
  facet_grid(months ~ .) +
  labs(x = "Probabilidad de Mordida", y = "Posterior", title = "Distribución Posterior por Número de Meses")
```

**Respuesta:**

Es difícil de interpretar por la forma en que esta graficado. Sin embargo, sí notamos que las menores probabilidades de perdida muestran un comportamiento más errático con el avance de los meses. Esto nos indica que a medida que avanzan los meses, la probabilidad de mordidad es menor, dado que el posterior genera cambios en su distribución respecto a estas menores probabilidades.

- [] Vuelva a aplicar grid approximation como el parte anterior, pero esta vez con prior uniforme y compare los resultados. ¿Qué puede decir sobre la elección de los priors?

```{r, eval=FALSE}
cols <- c("bites_month_1", "bites_month_2", "bites_month_3",
          "bites_month_4", "bites_month_5", "bites_month_6",
          "bites_month_7", "bites_month_8")

# Prior uniforme
grid_len <- 100
p_grid <- seq(0, 1, length.out = grid_len)  # Grid de probabilidades
prior <- rep(1, grid_len)  # Prior uniforme

posteriors <- c()
counted.months <- c()
p_grids <- rep(p_grid, 4)

for (n in c(1, 2, 4, 8)) {
  bites <- rowSums(as.matrix(dataMordidas[, 1:n]))

  likelihood <- dbinom(bites, size = n, prob = p_grid)
  
  unstd.posterior <- prior * likelihood
  posterior <- unstd.posterior / sum(unstd.posterior)
  
  posteriors <- c(posteriors, rep(posterior, grid_len))
  counted.months <- c(counted.months, rep(n, grid_len))
}

post.df <- data.frame("grid" = rep(p_grid, 4), "posterior" = posteriors, "months" = counted.months)

# Graficar los resultados
ggplot(post.df) +
  geom_line(aes(x = grid, y = posteriors)) +
  facet_grid(months ~ .) +
  labs(x = "Probabilidad de Mordida", y = "Posterior", title = "Distribución Posterior por Número de Meses")
```

**Respuesta:**

Vemos que el comportamiento anterior no se ve reflejado del todo. Aquí, la distribución del posterior parece mantenerse con el avance de los meses. Esto podría indicar que es importante la elección del prior, ya que, en este caso al menos, la elección de este cambia los resultados del análisis Bayesiano.

- [] Repita el mismo analisis anterior pero utilizando el metodo de Laplace (no necesita programar el metodo, puede utilizar la libreria "rethinking"). ¿Cómo se comparan con los resultados anteriores?

```{r, eval=FALSE}
for (n in c(1, 2, 4, 8)) {
  
  W <- sum(dataMordidas[, 1:n])
  L <- n * 250 - W
  
  # Adjust model
  res <- quap(
    alist(
      W ~ dbinom(L, p),  # Likelihood
      p ~ dunif(0, 1)    # Prior 
    ),
    data = list(W = W, L = L)
  )
  
  df <- precis(res)
  
  # Graph the posterior curves
  curve(dnorm(x, df$mean, df$sd), lty=2, add=FALSE, 
        xlab = "Probabilidad de mordida", ylab = "Densidad",
        main = paste("Distribución posterior - Meses:", n))
}
```

**Respuesta:**

Los resultados son más interpretables, ya que se observan directamente las densidades de las probabilidades. En este caso, Vemos que efectivamente suben las probabilidades respecto a su valor inicial (0) pero además tenemos un rango más cercano en el que estimar el cual es entre 0.6 y 0.7, dado que la distribución del posterior parece ser una gaussiana en ese rango.

- [] Grafique la densidad de la posterior y encuentre la proporción de los siguientes defined boundaries:

- [ ] $(0, 0.35)$
- [ ] $(0.35, 0.45)$
- [ ] $(0.45, 1)$

¿Cómo puede interpretar los resultados?

```{r, eval=FALSE}
grid_len <- 1000
p_grid <- seq(0, 1, length.out = grid_len)

prior <- dnorm(p_grid, mean = 0.6, sd = 0.05)

bites <- rowSums(as.matrix(dataMordidas[, 1:8]))

likelihood <- dbinom(bites, size = 8, prob = p_grid)

unstd.posterior <- prior * likelihood

posterior <- unstd.posterior / sum(unstd.posterior)

samples <- sample(p_grid, prob = posterior, size = 1e4, replace = TRUE)

dens(samples)

# Intervalos:
proporcion_0_035 <- mean(samples >= 0 & samples <= 0.35)
proporcion_035_045 <- mean(samples > 0.35 & samples <= 0.45)
proporcion_mayor_045 <- mean(samples > 0.45)

# Print proportions
cat("Proporción en el rango [0, 0.35]:", proporcion_0_035, "\n")
cat("Proporción en el rango (0.35, 0.45]:", proporcion_035_045, "\n")
cat("Proporción en el rango (>0.45):", proporcion_mayor_045, "\n")
```


**Respuesta:**

Los resultados parecen indicar una proporción mayor para la posterior cercana a 0.6. La proporción de los defined boundaries indica que la mayor parte de estas posteriores están en el rango mayor a 0.45. Esto nos indica que la probabilidad de mordida es mayor a este valor y es cercana a 0.6.


-[] Calcule un intervalo de credibilidad al $50%$, $75%$ y $95%$. ¿Como se puede interpretar los resultados? ¿Cual podría ser un problema al usar intervalos de credibilidad? 

```{r, eval=FALSE}
# Function to calculate credible interval for given prob
cred_interval <- function(samples, prob) {
  quantiles <- quantile(samples, probs = c((1 - prob) / 2, 1 - (1 - prob) / 2))
  return(quantiles)
}

# Calculate intervals
cred_50 <- cred_interval(samples, 0.50)
cred_75 <- cred_interval(samples, 0.75)
cred_95 <- cred_interval(samples, 0.95)
```

Intervalo $50\%$:
```{r, eval=FALSE}
cat("Intervalo de Credibilidad 50%: [", cred_50[1], ", ", cred_50[2], "]\n")
```

Intervalo $75\%$
```{r, eval=FALSE}
cat("Intervalo de Credibilidad 75%: [", cred_75[1], ", ", cred_75[2], "]\n")
```

Intervalo $95\%$
```{r, eval=FALSE}
cat("Intervalo de Credibilidad 95%: [", cred_95[1], ", ", cred_95[2], "]\n")
```

**Respuesta:**

Los resultados nos indican que podemos decir con importante certeza que la probabilidad se encuentra al menos en el rango entre 0.4 y 0.6. Un problema que pueden tener los intervalos de credibilidad es que estos dependen fuertemente de la elección del modelo, de los datos y de la elección del prior. En este caso, yo creo que los intervalos de credibilidad se están viendo afectados por la elección del prior, ya que este es centrado en 0.6. Claramente los intervalos tienden a incluir este valor.


- [ ] Genere los intervalos HDPI para $50%$, $75%$ y $95%$, compárelos con  los intervalos de credibilidad de la parte anterior. ¿En que se diferencian los intervalos de credibilidad con los HDPI? 

```{r}
# Calculate intervals with HPDI function from rethinking
hdpi_50 <- HPDI(samples, prob = 0.50)
hdpi_75 <- HPDI(samples, prob = 0.75)
hdpi_95 <- HPDI(samples, prob = 0.95)
```

Intervalo $50\%$:
```{r}
cat("Intervalo HDPI 50%: [", hdpi_50[1], ", ", hdpi_50[2], "]\n")
```


Intervalo $75\%$

```{r}
cat("Intervalo HDPI 75%: [", hdpi_75[1], ", ", hdpi_75[2], "]\n")
```

Intervalo $95\%$

```{r}
cat("Intervalo HDPI 95%: [", hdpi_95[1], ", ", hdpi_95[2], "]\n")
```

**Respuesta:**

Los intervalos son un poco más estrechos, pero sigue sin ser una diferencia demasiado sustantiva.

- [ ] Utilizando la posterior obtenida en la parte anterior, simule 10.000 réplicas de registros de mordidas. Compare la distribución del ratio de carteros mordidos predichos a partir de las réplicas con el ratio real de los datos. ¿El modelo se ajusta bien a los datos? Es decir, ¿la distribución de las predicciones incluye la observación real como resultado central y probable?

```{r, eval=FALSE}
bites <- rowSums(as.matrix(dataMordidas[, 1:8]))
n <- nrow(dataMordidas)
ratio.real <- sum(bites) / (n * 8)

simulated_bites <- sapply(samples, function(p) {
  rbinom(n, size = 8, prob = p)
})

simulated_ratios <- rowSums(simulated_bites) / (n * 8)

ggplot() +
  geom_density(aes(simulated_ratios)) + 
  geom_vline(aes(xintercept = ratio.real), color = "red") +
  labs(x = "Ratio de Carteros Mordidos", y = "Densidad", title = "Distribución de Ratios Simulados vs. Ratio Real")
```


**Respuesta:**



- [ ] Escoja cualquier par de meses consecutivos y obtenga la posterior de que una persona que fue mordida en el primer mes, sea mordida nuevamente en el segundo mes. Para esto, se recomienda comenzar buscando los carteros que fueron mordidos el primer mes y en base a estos generar una búsqueda indexada para obtener el número solicitado. Hecho esto simule ese número carteros mordidos 10.000 veces. De los resultados obtenidos, compare el recuento de carteros mordidos con el recuento real. ¿Cómo se ve el modelo desde este punto de vista?

```{r, eval=FALSE}


```

**Respuesta:**



---

### Pregunta 2:

En esta pregunta se trabajara con el dataset "notas.csv" el cual contiene las notas históricas de un curso desconocido. Suponga que los datos vienen de una distribución $\mathcal{N}(\mu,\sigma^2)$, el objetivo de la pregunta es estudiar el comportamiento de los datos y los posibles valores de $\mu,\sigma$ mediante técnicas de inferencia Bayesiana.

Usted sabe un dato extra sobre la información, $\sigma \in [0.5,1.5]$ y, además, tiene una fuerte creencia a que es mas probable encontrar la desviación estándar real entre $[0.5,1]$ que en $(1,1.5]$.


- [ ] Modifique el siguiente codigo que permite realizar una grid approximation para $2$ parámetros. Proponga priors para $\mu$ y $\sigma$, justifique su elección.


```{r}
# Leer información
data_notas <- read.csv("notas.csv")
data_vector <- as.numeric(data_notas$Notas)

# Función para crear likelihood dado mu y sigma
grid_function <- function(mu, sigma){
   sum(dnorm(data_vector, mean = mu, sd = sigma, log = TRUE))
}

# Valores de la grilla
grid_mu <- seq(1, 7, length.out = 100)
grid_sigma <- seq(0.5, 1.5, length.out = 100)

# Se crea la grilla 2d
data_grid <- expand_grid(grid_mu,grid_sigma)

# Se guarda la likelihod
data_grid$likelihood <- map2(data_grid$grid_mu,data_grid$grid_sigma, grid_function)

# Se transforma el forma de map2 a una columna
data_grid <- unnest(data_grid,cols = c("likelihood"))

# Valores de los priors
prior_mu <- rep(1, length(grid_mu))
# Se resta 0.5 para mantener el argumento de la distribución en [0,1]
prior_sigma <- dbeta(grid_sigma - 0.5, shape1 = 3, shape2 = 6)

# Se crea la grilla 2d de priors
prior <- expand_grid(prior_mu,prior_sigma)

# Se calculan los valores del prior
data_grid$prior <-  map2(prior$prior_mu,prior$prior_sigma, prod)
data_grid <- unnest(data_grid,cols = c("prior"))

# Se calcula el posterior
data_grid$unstd_posterior <-  data_grid$likelihood * data_grid$prior

# Se estandariza el posterior
data_grid$posterior <- data_grid$unstd_posterior/sum(data_grid$unstd_posterior)

# Se ajustan los valores de la posterior para que no sean valores tan pequeños
data_grid$posterior <- (data_grid$posterior - min(data_grid$posterior))/(max(data_grid$posterior)-min(data_grid$posterior))


```

**Respuesta:**

Para el parámetro $\mu$, que representa la media de las notas, se ha seleccionado un prior uniforme en el rango $([1, 7])$. Al no disponer de información previa que sugiera que ciertos valores de son más probables que otros, es conveniente el uso de esta prior en el intervalo de las notas, de 1 a 7.

Para el parámetro $\sigma$, correspondiente a la desviación estándar, se ha optado por un prior de distribución beta. La elección se fundamenta en la información adicional proporcionada, que indica que $\sigma$ se encuentra en el intervalo $([0.5, 1.5])$ y es más probable que tome valores entre $([0.5, 1])$ que en $((1, 1.5])$. Para representar esto, se ha optado los parámetros $\alpha = 3$ y $\beta = 8$ para aumentar la probabilidad dentro del rango $([0.5, 1])$. Graficamente:

```{r}
plot(grid_sigma, prior_sigma, type = "l", col = "blue",
     main = "Prior para sigma usando Beta(3, 8)",
     xlab = expression(sigma), ylab = "Densidad de probabilidad")

# Añadir una línea horizontal para referencia
abline(h = 0, col = "gray")
```

- [ ] Tras haber ejecutado el código de la parte anterior ejecute el siguiente, ¿Que puede decir de los valores de la distribución? Se recomienda hacer modificaciones en el código para realizar un mejor análisis y estudio.


```{r}

# Punto de referencia
valor_x <- mean(data_vector)
valor_y <- 0.8

# Gráfico
punto_comparacion <- tibble(x = valor_x, y = valor_y)

plt <- data_grid %>%
  ggplot(aes(x = grid_mu, y = grid_sigma)) +
  geom_raster(aes(fill = posterior),
    interpolate = T
  )+ 
  geom_point(x = valor_x, y = valor_y, size = 1.3,color="white")+
  geom_label(
    data = punto_comparacion, aes(x, y),
    label = "Punto Comparación",
    fill = "green",
    color = "black",
    nudge_y = 0, # Este parametro desplaza la caja por el eje y
    nudge_x = 1 # Este parametro desplaza la caja por el eje x
  )+
  scale_fill_viridis_c() +
  labs(
    title = "Posterior para Mean y Standard Deviation",
    x = expression(mu ["Mean"]),
    y = expression(sigma ["Standar Deviation"])
  ) +
  theme(panel.grid = element_blank())

plt
```


**Respuesta:**

La región de mayor probabilidad para $\mu$ se encuentra entre 1 y 3, mientras que para $\sigma$ la mayor densidad se concentra en el rango de 0.5 a 0.9. Esto sugiere que los datos observados tienden a estar centrados en valores bajos, con una variabilidad moderada. El prior utilizado para $\sigma$, basado en una distribución Beta(3, 8), favorece valores bajos, lo que se refleja en la forma adecuada del posterior respecto al punto de comparación en el eje de $\sigma$. Por el contrario, el prior uniforme para $\mu$ no parece haber sido el mejor, pues según el posterior, la media debería ser cercana al mínimo, cosa que no se corresponde con la media real, que oscila en torno al 6. De todas formas, sin ninguna información adicional, el prior uniforme seguía siendo buena opción, puesto que con algún otro modelo era posible quedar más lejos del valor real y empeorar aún más el resultado.


- [ ] A continuación se presenta un código que permite realizar la distribución dada por sampling from grid approximation ¿Para que sirve este proceso? ¿Que puede deducir del gráfico?


```{r}

# Codificamos los datos
x <- 1:length(data_grid$posterior)

# Sampleamos los indices
posterior_samples_aux <- sample(x,size = 1e4, replace = T, prob = data_grid$posterior)

# Obtenemos los verdaderos valores de la sampling distribution
posterior_samples <- data_grid[posterior_samples_aux,]

# Obtenemos solos los valores relevantes para la densidad
df <- data.frame(posterior_samples$grid_mu,posterior_samples$grid_sigma)

# Realizamos las densidades
dens(df)
```

**Respuesta:**

El proceso de "sampling from grid approximation" permite obtener muestras representativas del posterior usando la aproximación discreta calculada previamente en la cuadrícula. El posterior combina la verosimilitud de los datos y el prior, pero al usar una aproximación por cuadrícula, se evalúa en puntos discretos. El muestreo transforma esta representación discreta en una muestra continua, proporcionando una visión más precisa de la distribución posterior de los parámetros, lo que permite convertir el posterior discreto en una distribución continua de muestras, lo que facilita el análisis.

En los gráficos generados, se observa en el izquierdo la densidad de las muestras para $\mu$, que muestra un pico pronunciado alrededor de $\mu \approx 1.5$, lo que indica que los valores más probables para la media se encuentran en este rango. La distribución es asimétrica y decrece gradualmente a medida que $\mu$ aumenta, sugiriendo que aunque es posible encontrar medias mayores, estas son menos probables según los datos observados y el prior utilizado, en concordancia con el análisis previo.

En el gráfico derecho, que muestra la densidad para $\sigma$, se observa un pico alrededor de $\sigma \approx 0.8$, lo que indica que estos son los valores más probables para la desviación estándar, acorde a la creencia dada. La distribución es aproximadamente simétrica, con una caída rápida después de 1 y un límite inferior en 0.5, reflejando la influencia del prior que restringe $\sigma$ al intervalo $([0.5, 1.5]$.

---

### Pregunta 3: Regresión Lineal Bayesiana

El objetivo de esta pregunta es introducirlo en la aplicación de una regresión bayesiana. Con esto, buscaremos entender como calcular una regresión bayesiana en base al "motor" aproximación de Laplace, revisando como se comporta la credibilidad de sus predicciones y como la regresión lineal puede llegar a mutar a aplicar una transformación en el vector $x$. Para responder esta pregunta centre su desarrollo solo en las clases y las funciones que nos brinda la librería `rethinking`.

Para esta pregunta usaremos el dataset `Pokemon.csv`, que contiene las características de más de 700 personajes.

```{r, eval=FALSE}
poke.df <- read.csv("Pokemon.csv")
```


- [ ] Defina un modelo de regresión bayesiana para modelar `Sp..Atk` en función de `Attack`, definiendo sus propios priors. Comente cada una de sus asunciones y señale a través de ecuaciones el modelo.
- [ ] Ajuste el modelo lineal utilizando el método de Laplace approximation. Estudie a través del comando `precis` los resultados obtenidos y coméntelos.
- [ ] Gráfique el MAP de regresión lineal obtenida, añadiendo al gráfico el intervalo del $95\%$ que se tiene sobre la media y los valores predecidos de la altura. Comente los resultados obtenidos y señale si su modelo logra ser un buen predictor de los valores estudiados.

**Respuesta:**

Se utiliza un prior de media 100 y desviación estándar 50 para b0, basado en los valores observados en las variables y el conocimiento previo de los rangos en que suelen estar los ataques de los pokemones (entre 0 y 200, siempre positivos). Se asume también que la relación linear de la pendiente es no tan variable, es decir, con una pendiente 1 y variabilidad moderada de 0.5. Finalmente, se elige una desviación estándar conservadora, en el rango 0-200 mencionado anteriormente. Las ecuaciones del modelos son las del código que se encuentran en las alist model.

Además, el código realiza el ajusta mediante la aproximación de Laplace con el método quap, entregando la lista con los parámetros y priors definidos.

```{r, eval=FALSE}
# Model variables
data <- pokemon[, c("Sp..Atk", "Attack")]

# Bayesian model
# Equations for the model
model <- alist(
  Sp..Atk ~ dnorm(mu, sigma),   # Likelihood
  mu <- alpha + beta * Attack,  # Linear model
  alpha ~ dnorm(100, 50),         # Intercept Prior
  beta ~ dnorm(1, 0.5),          # Slope Prior
  sigma ~ dunif(0, 200)              # Standard Deviation Prior
)

# Fit the model with Laplace Approximation
fit <- quap(
  model,
  data = data
)

# Summary
precis(fit)

# Graph the model and uncertainty lines
plot(data$Attack, data$Sp..Atk, pch = 16, col = "blue", xlab = "Attack", ylab = "Sp..Atk")
post <- extract.samples(fit)
for (i in 1:100) {
  curve(post$alpha[i] + post$beta[i] * x, add = TRUE, col = alpha("red", 0.2))
}
```
Respecto a lo que nos da el comando precis:
1. Podemos decir que el intercepto parece razonable considerando el rango entre 0 y 200. La media de 41.31 nos indica que cuando el ataque es 0, el ataque especial esperado es 41.31. Esto es razonable, ya que es esperable que el ataque especial sea mucho mayor que el normal. Además, el intervalo de credibilidad parece razonable para ese mismo valor.

2. La pendiente parece mostrar un valor bajo entre 0.35 y 0.45. Esto nos indica que la relación entre attack y special attack es positiva, pero attack no es tan influyente en el valor de special attack y hay otras variables que influyen en esta última.

3. Una alta media para la desviación estándar, lo que nos indica que quizá, el modelo no captura completamente la variación de los datos. Esto sugiere, al igual que con la pendiente, que hay otros factores o variables relevantes que afectan a special attack en los datos.

Lo siguiente es el código que grafica el MAP de la regresión lineal con los intervalos del 95% que se tienen sobre la media y sobre el valor predecido de Sp..Atk. Los resultados son buenos, ya que el intervalo contiene a la mayoría de los valores y las líneas de incertidumbre. El modelo logra ser un buen predictor de los valores estudiados.

```{r, eval=FALSE}
ggplot() +
  geom_point(aes(x=poke.df$Attack, y=poke.df$Sp..Atk), color="red") +
  geom_line(aes(x=, y=), color="orange") +
  geom_ribbon(aes(x=, y=, ymin=, ymax=), alpha=0.3, fill="orange") +
  geom_ribbon(aes(x=, y=, ymin=, ymax=), alpha=0.1, fill="orange")

# Generate predictions on the fitted model
attack_seq <- seq(min(data$Attack), max(data$Attack), length.out = 100)

predicted_mean <- link(fit, data = list(Attack = attack_seq))

mean_pred <- apply(predicted_mean, 2, mean)
ci_mean <- apply(predicted_mean, 2, PI, prob = 0.95)

predicted_values <- sim(fit, data = list(Attack = attack_seq))

ci_pred <- apply(predicted_values, 2, PI, prob = 0.95)

plot(data$Attack, data$Sp..Atk, pch = 16, col = "blue", xlab = "Attack", ylab = "Sp..Atk")

# Graph lines and credible intervals
lines(attack_seq, mean_pred, col = "red", lwd = 2)

polygon(c(attack_seq, rev(attack_seq)),
        c(ci_mean[1, ], rev(ci_mean[2, ])),
        col = alpha("red", 0.2), border = NA)

polygon(c(attack_seq, rev(attack_seq)),
        c(ci_pred[1, ], rev(ci_pred[2, ])),
        col = alpha("blue", 0.2), border = NA)

legend("topleft", legend = c("Media predicha (MAP)", "IC 95% (media)", "IC 95% (valores)"),
       col = c("red", alpha("red", 0.2), alpha("blue", 0.2)), lwd = c(2, NA, NA), pch = c(NA, 15, 15),
       pt.cex = 2, bty = "n", cex = 0.8, bg = "white")
```



&nbsp;
<hr />
<p style="text-align: center;">A work by <a href="https://github.com/dccuchile/CC6104">CC6104</a></p>

<!-- Add icon library -->
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.1/css/all.css">

<!-- Add font awesome icons -->
<p style="text-align: center;">
    <a href="https://github.com/dccuchile/CC6104"><i class="fab fa-github" style='font-size:30px'></i></a>
</p>

<p style="text-align: center;">
    <a href="https://discord.gg/XCbQvGs3Uf"><i class="fab fa-discord" style='font-size:30px'></i></a>
</p>

&nbsp;